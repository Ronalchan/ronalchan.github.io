---
title: '基于高分辨率遥感图像的精细尺度下城市职住混合模式分析'
date: 2019-10-15
permalink: /posts/2019/10/project_1/
tags:
  - 深度学习
  - 职住混合模式
  - 遥感图像
---

## 基于高分辨率遥感图像的精细尺度下城市职住混合模式分析

由于缺乏足够的社交媒体数据和合适的模型，现有研究无法在精细尺度下描述城市职住混合模式。我们选取了基于卷积神经网络的改进模型BagNet来对高分辨率遥感图像进行分类。
遵循某app的用户协议，我们分析并获取了武汉市三百万的某app匿名用户的居住和工作位置，获取了武汉市部分小区的工作和居住的居民数量、通勤距离等特征。
通过对连续的用户数据进行分级处理，根据不同的职住属性标记遥感图像，然后采用过采样和多尺度随机采样结合的方法解决了遥感图像的多尺度问题和模型的过拟合问题，最后调整网络结构和调节参数。我们发现BagNet得到了较好的城市职住混合属性的拟合结果(OA>0.84，Kappa>0.8)。
**本次研究首次发现了基于深度学习可以挖掘高分辨率遥感图像中潜在的体现“职住平衡”的社会经济特征。通过和前人采用社交媒体数据的相关研究进行对比，本研究有力的说明“从顶向下”和“从底向上”两种城市社会经济研究的模式具有很好的辩证统一性**。

基于社交媒体数据提供了职住混合模式采样信息，本研究设计了一种基于深度学习模型，准确的挖掘高分辨率遥感影像中存在语义信息，有效的反应了城市的职住混合空间分布。本研究首次发现了高分辨率遥感影像和城市职住混合之间存在极强的相关关系，印证了两种不同的观测模式，即社会感知和卫星遥感，在表现城市社会经济特征时具有统一性和有效性。通过以武汉市为研究区，我们发现了武汉市呈现为典型的大中心组团结构，城市围绕中心城区周边区域，呈现中心辐射四周的发展结构，并且正在增加城市土地混合利用的程度。未来将从以下两个方面开展研究：耦合多源空间社交媒体数据进行职住混合模式分析和进一步调整和改进BagNet模型参数。本研究有利于认识城市内部职住空间模式，优化城市空间布局，有助于更好地服务城市规划和政府管理。

![](https://ronalchan.github.io/files/post/project_1_1.png)
<center>【图1 基于BagNet模型的职住混合模式分析流程图】</center>

![](https://ronalchan.github.io/files/post/project_1_2.png)
<center>【图2 武汉市地块级尺度的职住属性空间分布拟合结果：(A)中国地质大学 (B)汉口江滩 (C)光谷软件园】</center>

![](https://ronalchan.github.io/files/post/project_1_3.png)
<center>【图3 武汉市地块尺度的职住属性混合熵分布结果：(A)中国地质大学 (B)汉口江滩 (C)光谷软件园】</center>
